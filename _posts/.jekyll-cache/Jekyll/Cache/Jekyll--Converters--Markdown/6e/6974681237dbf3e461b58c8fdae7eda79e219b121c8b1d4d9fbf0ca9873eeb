I"~<p>Control variates are a class of methods for reducing the variance of a generic Monte Carlo estimator.</p>

<h2 id="introduction">Introduction</h2>

<p>Suppose we‚Äôd like to estimate the expectation of some function $f(x)$,</p>

\[A = \mathbb{E}[f(x)].\]

<p>A naive Monte Carlo approximation would proceed to estimate this expectation as a simple average over some number of samples:</p>

\[A \approx \frac{1}{n} \sum\limits_{i=1}^n f(x_i) =: \hat{S}.\]

<p>The variance of this approximation will be</p>

\[\mathbb{V}[\hat{S}] = \frac{\sigma^2_f}{n}\]

<p>where $\sigma^2_f$ is the variance of $f(x)$.</p>

<h2 id="control-variates">Control variates</h2>

<p>The idea behind control variates is to manipulate the approximation so that its expectation is still $A$, but it has lower variance. In particular, consider another function $g(x)$, where $\mathbb{E}[g(x)] = B$ (assuming we know this value upfront for now), and consider the random variable</p>

\[D = f(x) - c(g(x) - B)\]

<p>where $c$ is a scalar coefficient that we can choose for a given problem.</p>

<p>Notice that the expectation of $D$ is still $A$:</p>

<p>\begin{align} \mathbb{E}[D] &amp;= \mathbb{E}[f(x) - c(g(x) - B)] \\ &amp;= \mathbb{E}[f(x)] - c\mathbb{E}[g(x)] + cB \\ &amp;= \mathbb{E}[f(x)] - cB + cB \\ &amp;= \mathbb{E}[f(x)] \\ \end{align}</p>

<p>where we have used the fact that $\mathbb{E}[g(x)] = B$. So in effect, all we have done is added and subtracted the same term, to arrive back at $\mathbb{E}[f(x)]$. This might seem silly at first, but it actually helps us!</p>

<p>Recall that the variance of our original approximation was $\sigma^2_f$. The variance of our new random variable $D$ is</p>

<p>\begin{align} \mathbb{V}[D] &amp;= \mathbb{V}[f(x) - c g(x)  + c B] \\ &amp;= \mathbb{V}[f(x) - c g(x)] \\ &amp;= \mathbb{V}[f(x)] - 2c \text{cov}(f(x), g(x)) + c^2 \mathbb{V}[g(x)] \\ &amp;= \sigma^2_f - 2c \text{cov}(f(x), g(x)) + c^2 \sigma^2_g \\ \end{align}</p>

<p>where we have denoted $\sigma^2_g = \mathbb{V}[g(x)]$. Recall that $c$ is just a coefficient that we can set ourselves. Since we want to minimize variance, we can easily solve for the optimal value of $c$:</p>

<p>\begin{align} &amp;\frac{d}{d c} \left[\sigma^2_f - 2c \text{cov}(f(x), g(x)) + c^2 \sigma^2_g\right] = 0 \\ \implies&amp; -2 \text{cov}(f(x), g(x)) + 2c \sigma^2_g = 0 \\ \implies&amp; c^* = \frac{\text{cov}(f(x), g(x))}{\sigma^2_g} \\ \end{align}</p>

<p>Plugging in $c^*$, we can find the variance of $D$ at this optimal value:</p>

<p>\begin{align} \mathbb{V}[D] &amp;= \sigma^2_f - 2 \frac{\text{cov}(f(x), g(x))}{\sigma^2_g} \text{cov}(f(x), g(x)) + \left(\frac{\text{cov}(f(x), g(x))}{\sigma^2_g}\right)^2 \sigma^2_g \end{align}</p>

<p>Simplifying, and denoting the correlation between $f$ and $g$ as $\rho_{fg} = \frac{\text{cov}(f(x), g(x))}{\sigma_f\sigma_g}$, we have</p>

\[\mathbb{V}[D] = \sigma^2_f(1 - \rho_{fg}^2).\]

<p>So the variance is reduced by a multiplicative factor of $1-\rho_{fg}^2$, implying that we‚Äôll see a greater reduction in variance if we choose a function $g$ that is more correlated with $f$.</p>

<p>Now, instead of estimating $\hat{S}$ as a sample mean, let‚Äôs compute an approximation of $\mathbb{E}[D]$:</p>

\[\mathbb{E}[D] \approx \frac{1}{n} \sum\limits_{i=1}^n \left[f(x_i) - c g(x_i)\right] + B,\]

<p>which will reduce the variance of our naive estimator.</p>

<h2 id="references">References</h2>

<ul>
  <li>Professor Jonathan Goodman‚Äôs <a href="https://www.math.nyu.edu/faculty/goodman/teaching/MonteCarlo2005/notes/VarianceReduction.pdf">notes on variance reduction methods</a>.</li>
  <li>Tucker, George, et al. ‚ÄúRebar: Low-variance, unbiased gradient estimates for discrete latent variable models.‚Äù Advances in Neural Information Processing Systems. 2017.</li>
  <li>Paisley, John, David Blei, and Michael Jordan. ‚ÄúVariational Bayesian inference with stochastic search.‚Äù arXiv preprint arXiv:1206.6430 (2012).</li>
</ul>

:ET