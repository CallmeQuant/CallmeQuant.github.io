I"È<p>Tweedie distributions are a very general family of distributions that includes the Gaussian, Poisson, and Gamma (among many others) as special cases.</p>

<h2 id="exponential-dispersion-models">Exponential dispersion models</h2>

<p>Exponential dispersion models (EDMs) have the following form:</p>

\[f(x; \mu, \sigma^2) = h(\sigma^2, x) \exp\left(\frac{\theta x - A(\theta)}{\sigma^2}\right)\]

<p>where $h(\sigma^2, x)$ is the ‚Äúbase distribution‚Äù, $\theta(\mu, \sigma^2)$ is a combination/function of the parameters, and $A(\theta)$ is the normalization quantity.</p>

<p>Notice that if we treat $\sigma^2$ as constant, this reduces to the natural exponential family, which has the form
\(f(x; \mu) = h(x) \exp\left(\widetilde{\theta} x - A(\widetilde{\theta})\right).\)
In this way, we can view EDMs as a generalization of the exponential family that allow for varying dispersion (hence the name).</p>

<p>The mean and variance of an EDM-distributed random variable $X$ are
\begin{align} \mathbb{E}[X] &amp;= \mu = A^\prime(\theta) \\ \mathbb{V}[X] &amp;= \sigma^2 A^{\prime \prime}(\theta) = \sigma^2 V(\mu) \end{align}
where $V(\mu)$ is called the ‚Äúvariance function‚Äù.</p>

<h2 id="tweedie">Tweedie</h2>

<p>Tweedie families are a special case of the EDMs discussed above. Specifically, Tweedie distributions make an assumption about the relationship between the mean and the variance of the distribution. To specify a Tweedie distribution, another parameter $p \in \mathbb{R}$ is introduced, and we restrict the variance as:
\(\mathbb{V}[X] = \sigma^2 V(\mu) = \sigma^2 \mu^p.\)</p>

<p>If $X$ is Tweedie-distributed with power parameter $p$, we write
\(X \sim \text{Tw}_p(\mu, \sigma^2).\)</p>

<p>Given a value of $p$, writing down the pdf requires finding the proper base measure $h(\mu, \sigma^2)$ such that the density normalizes to 1 properly. In general, this is difficult for the Tweedie family, but we show a few special cases below.</p>

<h2 id="special-cases">Special cases</h2>

<h3 id="gaussian-p--0">Gaussian ($p = 0$)</h3>

<p>Let $X \sim \text{Tw}_{p}(\mu, \sigma^2)$ where $p=0$. Then the variance is given by $\mathbb{V}[X] = \sigma^2$. Let $\theta = \frac12 \mu$, $A(\theta) = \frac12 \theta^2 = \frac12 \mu^2$ 
\(h(x; \mu, \sigma^2) = \frac{\exp(-\frac{1}{2\sigma^2} x^2)}{\sqrt{2 \pi \sigma^2}}.\)
Notice that $A^{\prime\prime}(\theta) = 1$, which implies that 
\(\mathbb{V}[X] = \sigma^2 A^{\prime\prime}(\theta) = \sigma^2 \cdot 1 = \sigma^2 \cdot 1^0\)
so we have satisifed the mean-variance relationship.</p>

<p>Then we have
\begin{align} f(x; \mu, \sigma^2) &amp;= \frac{\exp(-\frac{1}{2\sigma^2} x^2)}{\sqrt{2 \pi \sigma^2}} \exp\left( \frac{\frac12 \mu x - \frac12 \mu^2}{\sigma^2} \right) \\ &amp;= \frac{1}{\sqrt{2 \pi \sigma^2}} \exp\left( \frac{-\frac{1}{2\sigma^2} x^2 + \frac12 \mu x - \frac12 \mu^2}{\sigma^2} \right) \\ &amp;= \frac{1}{\sqrt{2 \pi \sigma^2}} \exp\left( -\frac{1}{2\sigma^2} (x^2 - \mu x + \mu^2) \right) \\ &amp;= \frac{1}{\sqrt{2 \pi \sigma^2}} \exp\left( -\frac{1}{2\sigma^2} (x - \mu)^2 \right) \\ \end{align}
which is the density for a Gaussian random variable with mean $\mu$ and variance $\sigma^2$.</p>

<h3 id="poisson-p1-sigma21">Poisson ($p=1, \sigma^2=1$)</h3>

<p>Let $X \sim \text{Tw}_{p}(\mu, \sigma^2)$ where $p=1$ and we set $\sigma^2 = 1$ to be a constant. Then the variance is given by $\mathbb{V}[X] = \sigma^2 \mu^1 = \mu$, implying that the mean and variance are equal.</p>

<p>Since $\sigma^2 = 1$, the density‚Äôs general form reduces to
\(f(x; \mu) = h(x) \exp\left(\theta x - A(\theta)\right).\)</p>

<p>Let $\theta = \log \mu$, $h(x) = \frac{1}{x!}$, $A(\theta) = e^\theta$. Then we have
\begin{align} f(x; \mu) &amp;= \frac{1}{x!} \exp\left(x \log \mu - e^\theta) \right) \\ &amp;= \frac{1}{x!} \exp(\log \mu^x)) \exp(e^{-\log \mu}) \\ &amp;= \frac{1}{x!} \mu^x e^{-\mu} \end{align}
which is the density of a Poisson-distributed random variable with rate parameter $\mu$.</p>

<p>Notice that 
\(\mathbb{V}[X] = \sigma^2 A^{\prime\prime}(\theta) = \sigma^2 e^\theta = \sigma^2 e^{\log \mu} = \sigma^2 \mu = \sigma^2 \cdot \mu^1 = \sigma^2 \cdot \mu^p\)
so we have satisfied the mean-variance relationship (in the case of the Poisson, they‚Äôre identical).</p>

<h3 id="gamma-p2">Gamma ($p=2$)</h3>

<p>Let $X \sim \text{Tw}_{p}(\mu, \sigma^2)$ where $p=2$. The variance of $X$ is then $\mathbb{V}[X] = \sigma^2 \mu^2$.</p>

<p>Let $\theta = -\mu \sigma^2$, $A(\theta) = -\log (-\theta)$, and $h(x; \mu, \sigma^2) = \frac{x^{1/\sigma^2 - 1}}{\Gamma(1/\sigma^2) (\sigma^2)^{1/\sigma^2}}$. Then the density is
\begin{align} f(x; \mu, \sigma^2) &amp;= h(\sigma^2, x) \exp\left(\frac{\theta x - A(\theta)}{\sigma^2}\right) \\ &amp;= \frac{x^{1/\sigma^2 - 1}}{\Gamma(1/\sigma^2) (\sigma^2)^{1/\sigma^2}} \exp\left( \frac{-\mu \sigma^2 x + \log(-\theta)}{\sigma^2} \right) \\ &amp;= \frac{x^{1/\sigma^2 - 1}}{\Gamma(1/\sigma^2) (\sigma^2)^{1/\sigma^2}} \exp\left( -\mu x + \frac{1}{\sigma^2} \log(\mu \sigma^2) \right) \\ &amp;= \frac{x^{1/\sigma^2 - 1}}{\Gamma(1/\sigma^2) (\sigma^2)^{1/\sigma^2}} e^{-\mu x}\exp\left( \log(\mu^{1/\sigma^2} + \log(\sigma^2)^{1/\sigma^2} \right) \\ &amp;= \frac{x^{1/\sigma^2 - 1}}{\Gamma(1/\sigma^2) (\sigma^2)^{1/\sigma^2}} e^{-\mu x} \mu^{1/\sigma^2} (\sigma^2)^{1/\sigma^2} \\ &amp;= \frac{x^{1/\sigma^2 - 1} }{\Gamma(1/\sigma^2)} e^{-\mu x} \mu^{1/\sigma^2} \\ \end{align}
which is the density of a Gamma-distributed random variable with shape $1/\sigma^2$ and rate $\mu$.</p>

<h2 id="references">References</h2>

<ul>
  <li>Wikipedia pages on <a href="https://www.wikiwand.com/en/Tweedie_distribution">Tweedie distributions</a> and <a href="https://www.wikiwand.com/en/Exponential_dispersion_model">exponential dispersion models</a></li>
  <li>Seth David Temple‚Äôs <a href="https://math.uoregon.edu/wp-content/uploads/2018/07/TempleStempleTweedieThesis.pdf">thesis, The Tweedie Index Parameter and Its Estimator</a></li>
  <li>Bonat, Wagner H., et al. ‚ÄúExtended Poisson‚ÄìTweedie: Properties and regression models for count data.‚Äù Statistical Modelling 18.1 (2018): 24-49.</li>
</ul>
:ET